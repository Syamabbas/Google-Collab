{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Syamabbas/Google-Collab/blob/main/Auto_Labeling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "OVBLBFE3ww6a"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from datetime import timedelta\n",
        "from collections import defaultdict\n",
        "\n",
        "df = pd.read_excel(\"/content/drive/MyDrive/Google Collab/Data Cleansing Sym.xlsx\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "REFERENCE_DATE = pd.Timestamp(\"2025-12-01\")\n",
        "\n",
        "def convert_relative_time(text, ref_date=REFERENCE_DATE):\n",
        "    if pd.isna(text):\n",
        "        return None\n",
        "\n",
        "    text = str(text).lower().strip()\n",
        "    text = text.replace(\"diedit\", \"\").strip()\n",
        "\n",
        "    special_map = {\n",
        "        \"sebulan lalu\": (\"bulan\", 1),\n",
        "        \"seminggu lalu\": (\"minggu\", 1),\n",
        "        \"setahun lalu\": (\"tahun\", 1)\n",
        "    }\n",
        "\n",
        "    if text in special_map:\n",
        "        unit, value = special_map[text]\n",
        "    else:\n",
        "        match = re.search(r\"(\\d+)\\s+(menit|jam|hari|minggu|bulan|tahun)\\s+lalu\", text)\n",
        "        if not match:\n",
        "            return None\n",
        "        value = int(match.group(1))\n",
        "        unit = match.group(2)\n",
        "\n",
        "    if unit == \"menit\":\n",
        "        return ref_date - timedelta(minutes=value)\n",
        "    elif unit == \"jam\":\n",
        "        return ref_date - timedelta(hours=value)\n",
        "    elif unit == \"hari\":\n",
        "        return ref_date - timedelta(days=value)\n",
        "    elif unit == \"minggu\":\n",
        "        return ref_date - timedelta(weeks=value)\n",
        "    elif unit == \"bulan\":\n",
        "        return ref_date - pd.DateOffset(months=value)\n",
        "    elif unit == \"tahun\":\n",
        "        return ref_date - pd.DateOffset(years=value)\n",
        "\n",
        "    return None"
      ],
      "metadata": {
        "id": "vp8AYJsisTrr"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['tanggal_review'] = df['Waktu'].apply(convert_relative_time)\n",
        "df['tanggal_review'] = pd.to_datetime(df['tanggal_review']).dt.date"
      ],
      "metadata": {
        "id": "Hs2ODi8wsflq"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LOAD KAMUS TYPO\n",
        "sheet_id = \"12ypDLePiU0f-50wsfsQ8N21aWLjmeb8q5k9L8tn4YIU\"\n",
        "\n",
        "def load_gsheet(sheet_name):\n",
        "    url = f\"https://docs.google.com/spreadsheets/d/{sheet_id}/gviz/tq?tqx=out:csv&sheet={sheet_name}\"\n",
        "    return pd.read_csv(url)\n",
        "\n",
        "# url = f\"https://docs.google.com/spreadsheets/d/12ypDLePiU0f-50wsfsQ8N21aWLjmeb8q5k9L8tn4YIU/gviz/tq?tqx=out:csv&sheet=Kamus_Typo\"\n",
        "\n",
        "typo_df = load_gsheet(\"Kamus_Typo\")\n",
        "\n",
        "# pastikan lowercase & tidak ada NaN\n",
        "typo_df['Typo'] = typo_df['Typo'].astype(str).str.lower().str.strip()\n",
        "typo_df['Correction'] = typo_df['Correction'].astype(str).str.lower().str.strip()\n",
        "\n",
        "# convert ke dictionary\n",
        "typo_dict = dict(zip(typo_df['Typo'], typo_df['Correction']))\n",
        "\n",
        "print(f\"Total typo loaded: {len(typo_dict)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "URhcBXQQ82mt",
        "outputId": "3dee79c4-d3ef-4de1-daec-9414c9b36396"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total typo loaded: 115\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PATTERN NORMALIZATION\n",
        "patterns = {\n",
        "    r'(\\d+)\\s*hri': r'\\1 hari',\n",
        "    r'(\\d+)\\s*hr': r'\\1 hari',\n",
        "    r'(\\d+)\\s*d': r'\\1 hari'\n",
        "}"
      ],
      "metadata": {
        "id": "3h3NBjLw_1eo"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CLEANING FUNCTIONS\n",
        "def clean_text(text):\n",
        "    text = str(text).lower()\n",
        "    text = re.sub(r'http\\S+', '', text)\n",
        "    text = re.sub(r'[^a-z0-9\\s]', ' ', text)\n",
        "    text = re.sub(r'(.)\\1{2,}', r'\\1', text)  # huruf berulang\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text\n",
        "\n",
        "def normalize_pattern(text):\n",
        "    for p, rpl in patterns.items():\n",
        "        text = re.sub(p, rpl, text)\n",
        "    return text\n",
        "\n",
        "def normalize_typo(text):\n",
        "    for typo, correct in typo_dict.items():\n",
        "        text = re.sub(rf'\\b{re.escape(typo)}\\b', correct, text)\n",
        "    return text"
      ],
      "metadata": {
        "id": "bJ7cfzUp_9NY"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# APPLY TO DATAFRAME\n",
        "df['clean_text'] = df['Komentar'].apply(clean_text)\n",
        "df['clean_text'] = df['clean_text'].apply(normalize_pattern)\n",
        "df['clean_text'] = df['clean_text'].apply(normalize_typo)"
      ],
      "metadata": {
        "id": "HOZdu6fG__jU"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LOAD KAMUS SENTIMENT FROM GOOGLE SHEET\n",
        "sentiment_df = load_gsheet(\"Kamus_Sentiment\")\n",
        "\n",
        "# normalisasi\n",
        "sentiment_df['keyword'] = sentiment_df['keyword'].astype(str).str.lower().str.strip()\n",
        "sentiment_df['sentiment'] = sentiment_df['sentiment'].astype(str).str.lower().str.strip()\n",
        "\n",
        "# pisahkan positive & negative\n",
        "positive_words = sentiment_df[sentiment_df['sentiment'] == 'positif']['keyword'].tolist()\n",
        "negative_words = sentiment_df[sentiment_df['sentiment'] == 'negatif']['keyword'].tolist()\n",
        "\n",
        "print(\"Positive words:\", len(positive_words))\n",
        "print(\"Negative words:\", len(negative_words))"
      ],
      "metadata": {
        "id": "WVoeqHf_xIJg"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def auto_label(text, pos_words, neg_words):\n",
        "    pos_count = 0\n",
        "    neg_count = 0\n",
        "\n",
        "    for word in pos_words:\n",
        "        if word in text:\n",
        "            pos_count += 1\n",
        "\n",
        "    for word in neg_words:\n",
        "        if word in text:\n",
        "            neg_count += 1\n",
        "\n",
        "    if pos_count > neg_count:\n",
        "        return \"positif\"\n",
        "    elif neg_count > pos_count:\n",
        "        return \"negatif\"\n",
        "    else:\n",
        "        return \"netral\""
      ],
      "metadata": {
        "id": "eKIr8FJkxhJM"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['label'] = df['clean_text'].apply(\n",
        "    lambda x: auto_label(x, positive_words, negative_words)\n",
        ")\n",
        "\n",
        "df[['Komentar', 'label']]"
      ],
      "metadata": {
        "id": "M4mWIuGvOKPT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ml = df[df['label'] != 'netral'].copy()"
      ],
      "metadata": {
        "id": "Q5L4_h_D0FxH"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def auto_label_with_score(text, pos_words, neg_words):\n",
        "    pos_count = sum(1 for w in pos_words if w in text)\n",
        "    neg_count = sum(1 for w in neg_words if w in text)\n",
        "    score = abs(pos_count - neg_count)\n",
        "\n",
        "    if pos_count > neg_count:\n",
        "        return \"positif\", score\n",
        "    elif neg_count > pos_count:\n",
        "        return \"negatif\", score\n",
        "    else:\n",
        "        return \"netral\", 0\n"
      ],
      "metadata": {
        "id": "4Udh-pek0Ia_"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[['label','confidence']] = df['clean_text'].apply(\n",
        "    lambda x: pd.Series(\n",
        "        auto_label_with_score(x, positive_words, negative_words)\n",
        "    )\n",
        ")\n",
        "\n",
        "df_ml = df[df['confidence'] >= 1].copy()"
      ],
      "metadata": {
        "id": "ZrNrYWTrPMp-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "positive_words = sorted(positive_words, key=len, reverse=True)\n",
        "negative_words = sorted(negative_words, key=len, reverse=True)"
      ],
      "metadata": {
        "id": "vOZHo230O_NO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "# Simpan ke Excel\n",
        "file_name = \"hasil_auto_labeling.xlsx\"\n",
        "df_ml.to_excel(file_name, index=False)\n",
        "\n",
        "# Download\n",
        "files.download(file_name)\n",
        "print(\"File berhasil dibuat dan sedang diunduh!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "ZDMALabR-gjA",
        "outputId": "1b439d49-f135-4a3d-b30e-bd6883c045ef"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_550656aa-4994-4ee5-b73d-5dcbfa919e8a\", \"hasil_auto_labeling.xlsx\", 388060)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File berhasil dibuat dan sedang diunduh!\n"
          ]
        }
      ]
    }
  ]
}